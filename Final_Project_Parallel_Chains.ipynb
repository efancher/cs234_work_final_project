{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaPOMDP`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaPOMDP/Registry`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Some registries failed to update:\n",
      "│     — /Users/efan/.julia/registries/General — failed to fetch from repo\n",
      "│     — /Users/efan/.julia/registries/JuliaPOMDP — failed to fetch from repo\n",
      "└ @ Pkg.API /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Pkg/src/API.jl:144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Cloning\u001b[22m\u001b[39m registry from \"https://github.com/JuliaPOMDP/Registry\"\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %=========>                               ]  21.4 %]  42.7 %==========================>              ]  64.1 %]  85.3 %> ]  96.6 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: registry `JuliaPOMDP` already exists in `~/.julia/registries`\n",
      "└ @ POMDPs /Users/efan/.julia/packages/POMDPs/JiYXY/src/utils.jl:65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using POMDPs\n",
    "using Random # for AbstractRNG\n",
    "using POMDPModelTools\n",
    "using Pkg\n",
    "\n",
    "using DataFrames\n",
    "Pkg.add(\"JSON\")\n",
    "\n",
    "POMDPs.add_registry()\n",
    "using Pkg; Pkg.add(\"DiscreteValueIteration\")\n",
    "\n",
    "using DiscreteValueIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"StaticArrays\")\n",
    "using POMDPSimulators\n",
    "using POMDPPolicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setup_agents (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "include(\"./ParallelChains.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chains = 5\n",
    "num_states = 6\n",
    "r_mean = 5.0\n",
    "r_std = 2.0\n",
    "\n",
    "true_values = DataFrame(theta = [r_mean for i in 1:num_chains],\n",
    "                        std = [r_std  for i in 1:num_chains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPSimulators\n",
    "using POMDPPolicies\n",
    "rng = MersenneTwister(1235);\n",
    "\n",
    "PParallelChainMDP() = PParallelChainMDP(num_states+1,num_chains, .9,\n",
    "\n",
    "        true_values.theta,\n",
    "        true_values.std,\n",
    "        MersenneTwister(1235))\n",
    "m = PParallelChainMDP()\n",
    "\n",
    "# policy that maps every input to an action\n",
    "policy = FunctionPolicy(s->3)\n",
    "for i in 1:3\n",
    "    for (s, a, r) in stepthrough(m, policy, \"s,a,r\", max_steps=10)\n",
    "      render(m, (s,a,r))\n",
    "      println(\"s,a,r:($s,$a,$r)\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curry(f, a) = (xs...) -> f(a, xs...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPSimulators\n",
    "using POMDPPolicies\n",
    "rng = MersenneTwister(1235);\n",
    "\n",
    "num_chains = 10\n",
    "num_states = 30\n",
    "r_mean = 5.0\n",
    "r_std = 2.0\n",
    "@requirements_info ValueIterationSolver() PParallelChainMDP(num_states+1,num_chains, .9,\n",
    "\n",
    "        randn(rng, Float32, num_chains) .* r_std .+ r_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chains=2\n",
    "r_mean = 0\n",
    "r_std = 1\n",
    "## sigma is 1\n",
    "## Reward is noisy ~ N(theta_c, sigma^2)\n",
    "## Initial prior mean is N(theta_c, sigma^2 + c)\n",
    "rng = MersenneTwister(1235)\n",
    "th_c = [randn(rng, Float64, 1)[1] * (100 + i) for i in 1:num_chains]\n",
    "println(th_c)\n",
    "true_values = DataFrame(theta = th_c,\n",
    "                         std = [r_std  for i in 1:num_chains])\n",
    "mdp = PParallelChainMDP(num_states+1,num_chains, .9,\n",
    "        true_values.theta,\n",
    "        true_values.std, \n",
    "        rng)\n",
    "# @requirements_info ValueIterationSolver() mdp\n",
    "solver = ValueIterationSolver(max_iterations=100, belres=1e-6, include_Q=true, verbose=true) # initializes the Solver type\n",
    "vip = solve(solver, mdp) # runs value iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip.qmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearIndices((num_chains, num_states))[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in 1:num_chains\n",
    "    println(\"q value for (1,1),$i is $(vip.qmat[LinearIndices((num_chains, num_states))[1,1],i])\")\n",
    "    println(\"q value for $((i,num_states)),1 is $(vip.qmat[LinearIndices((num_chains, num_states))[i,num_states],1])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp.Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPSimulators\n",
    "using POMDPPolicies\n",
    "\n",
    "\n",
    "\n",
    "for (s, a, r) in stepthrough(mdp, vip, \"s,a,r\", max_steps=40)\n",
    "    render(mdp, (s,a,r))\n",
    "    println(\"s,a,r:($s,$a,$r)\")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucb_pol (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ucb_pol(li, policy, priors, i, actions, s)\n",
    "    best_action = action(policy, s)\n",
    "    #println(\"in state: $s, best action:$best_action\")\n",
    "    return action(policy, s)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = LinearIndices((num_chains, num_states))\n",
    "function ucb_update_priors(priors, history, i)\n",
    "    return priors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucb_mdp_builder (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curry(f, x) = (xs...) -> f(x, xs...)\n",
    "function ucb_mdp_builder(true_mdp, priors, i, num_states, num_chains, steps)\n",
    "  # build mdp\n",
    "  new_means = priors.theta + priors.std\n",
    "  rng = MersenneTwister(1233)\n",
    "  #println(\"new means: $new_means, std: $(priors.std), num_chains:$num_chains, num_states:$num_states, i:$i, mdp:$(typeof(true_mdp))\")\n",
    "  # (randn(p.rng, Float32, 1) .* p.Rs_means[s[1]]  .+ p.Rs_means[s[1]])[1]\n",
    "  mdp = PParallelChainMDP(num_states+1,num_chains, .9,\n",
    "        [randn(rng, Float32,1)[1] * priors.theta[j] + priors.std[j] for j in 1:num_chains])\n",
    "  #println(\"#2\")\n",
    "  # solve mdp\n",
    "  #println(\"#3\")\n",
    "  solver = ValueIterationSolver(max_iterations=1000, belres=1e-6, include_Q=true)#, verbose=true) # initializes the Solver type\n",
    "  vip = solve(solver, mdp)\n",
    "  li = LinearIndices((num_chains, num_states))\n",
    "  #print(\"policy q: $(vip.qmat)\")\n",
    "  new_policy = FunctionPolicy(curry(curry(curry(curry(curry(ucb_pol, li), vip), priors),i), actions))\n",
    "  # print(\"new policy: $new_policy\")\n",
    "  # return iterator solved mdp\n",
    "  return Iterators.Stateful(stepthrough(deepcopy(true_mdp), new_policy, \"s,a,r,sp,t\",\n",
    "                            max_steps=steps))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "do_update_priors() =  false\n",
    "update_priors() = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "do_runs (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "include(\"./ParallelChains.jl\")\n",
    "using Distributions\n",
    "function do_runs(nruns, num_agents, num_chains, num_states, H, update_priors_check, update_priors, mdp_iter_builder)\n",
    "    # UCB\n",
    "\n",
    "    # setup constants here\n",
    "    num_agents = num_agents\n",
    "    num_chains = num_chains\n",
    "    num_states = num_states\n",
    "    epochs = 1\n",
    "    nruns = nruns\n",
    "    H = H\n",
    "\n",
    "    # So best idea:\n",
    "    # for ucb:\n",
    "    # we generate an mdp with mu + sigma rewards (priors) for each end node.\n",
    "    #  we collect history until the criteria in PAC-EXPLORE then update the prior\n",
    "    # \n",
    "    # for thompson sampling\n",
    "    # at each time step (might skip this for this problem and save for max rew path) \n",
    "    #   take rewards and use to create a posterior.\n",
    "    # for seed sampling\n",
    "    # at beginning of episode\n",
    "    #   each agent generates a new random \"seed\" \n",
    "    #   at each time step\n",
    "    #     each agent generates a new mdp based on a deterministic mapping from seed to rewards (which also takes\n",
    "    #              history into account)\n",
    "    # this needs to update the actual reward.\n",
    "\n",
    "    ## PC notes\n",
    "    ## theta_c ~ N(0, 100 + c)\n",
    "    r_mean = 0\n",
    "    r_std = 1\n",
    "    ## sigma is 1\n",
    "    ## Reward is noisy ~ N(theta_c, sigma^2)\n",
    "    ## Initial prior mean is N(theta_c, sigma^2 + c)\n",
    "    rng = MersenneTwister(1236)\n",
    "    base = 10 # 100  # lowered a bit for testing\n",
    "    runs = []\n",
    "    true_values_list = DataFrame( run = [],\n",
    "                                 c = [],\n",
    "                                 theta = [],\n",
    "                                 std = [])\n",
    "    for run in 1:nruns\n",
    "        th_c = [randn(rng, Float64, 1)[1] * sqrt(base + i) for i in 1:num_chains]\n",
    "        #th_c[1] = 300\n",
    "        println(th_c)\n",
    "        true_values = DataFrame( run = [run for i in 1:num_chains],\n",
    "                                 c = [i for i in 1:num_chains],\n",
    "                                 theta = th_c,\n",
    "                                 std = [r_std  for i in 1:num_chains])\n",
    "        print(\"true mdp: $true_values\")\n",
    "        priors = DataFrame(theta = [true_values.theta[i] for i in 1:num_chains],\n",
    "                           std = [r_std + i for i in 1:num_chains],\n",
    "                           state = [(chain,num_states) for chain in 1:num_chains])\n",
    "        print(\"priors: $priors\")\n",
    "        mdp = PParallelChainMDP(num_states+1,num_chains, .9,\n",
    "                true_values.theta)\n",
    "        do_update_priors() =  false\n",
    "        # priors = randn(rng, Float32, num_chains) .* (r_std + c) .+ r_mean\n",
    "        hist = run_chain!(\n",
    "                   mdp_iter_builder=mdp_iter_builder,\n",
    "                   true_mdp=mdp,\n",
    "                   do_update_priors=update_priors_check,\n",
    "                   update_priors=update_priors,\n",
    "                   priors=priors,\n",
    "                   n_agents=num_agents,\n",
    "                   num_states=num_states,\n",
    "                   num_chains=num_chains,\n",
    "                   epochs=epochs,\n",
    "                   steps=H) #,\n",
    "                   #rev_action_map=rev_action_map)\n",
    "        #print(Q_tables)\n",
    "        println(\"(e,i,t,st,r)\")\n",
    "        hist\n",
    "        for (e, ag, t, st, r)  in hist\n",
    "          push!(runs, (run, e, ag, t, st, r)) \n",
    "        end\n",
    "        append!(true_values_list, true_values)\n",
    "\n",
    "    end\n",
    "    return (true_values_list, runs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.54912, 0.815592, -0.576327, 2.55318, -3.81941, 2.93883, -2.47224, 0.579177, -7.63242, 1.48565]\n",
      "true mdp: 10×4 DataFrame\n",
      "│ Row │ run   │ c     │ theta     │ std   │\n",
      "│     │ Int64 │ Int64 │ Float64   │ Int64 │\n",
      "├─────┼───────┼───────┼───────────┼───────┤\n",
      "│ 1   │ 1     │ 1     │ -4.54912  │ 1     │\n",
      "│ 2   │ 1     │ 2     │ 0.815592  │ 1     │\n",
      "│ 3   │ 1     │ 3     │ -0.576327 │ 1     │\n",
      "│ 4   │ 1     │ 4     │ 2.55318   │ 1     │\n",
      "│ 5   │ 1     │ 5     │ -3.81941  │ 1     │\n",
      "│ 6   │ 1     │ 6     │ 2.93883   │ 1     │\n",
      "│ 7   │ 1     │ 7     │ -2.47224  │ 1     │\n",
      "│ 8   │ 1     │ 8     │ 0.579177  │ 1     │\n",
      "│ 9   │ 1     │ 9     │ -7.63242  │ 1     │\n",
      "│ 10  │ 1     │ 10    │ 1.48565   │ 1     │priors: 10×3 DataFrame\n",
      "│ Row │ theta     │ std   │ state    │\n",
      "│     │ Float64   │ Int64 │ Tuple…   │\n",
      "├─────┼───────────┼───────┼──────────┤\n",
      "│ 1   │ -4.54912  │ 2     │ (1, 10)  │\n",
      "│ 2   │ 0.815592  │ 3     │ (2, 10)  │\n",
      "│ 3   │ -0.576327 │ 4     │ (3, 10)  │\n",
      "│ 4   │ 2.55318   │ 5     │ (4, 10)  │\n",
      "│ 5   │ -3.81941  │ 6     │ (5, 10)  │\n",
      "│ 6   │ 2.93883   │ 7     │ (6, 10)  │\n",
      "│ 7   │ -2.47224  │ 8     │ (7, 10)  │\n",
      "│ 8   │ 0.579177  │ 9     │ (8, 10)  │\n",
      "│ 9   │ -7.63242  │ 10    │ (9, 10)  │\n",
      "│ 10  │ 1.48565   │ 11    │ (10, 10) │e: 1, t: 10, agent 1, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 1 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 2, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 2 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 3, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 3 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 4, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 4 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 5, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 5 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 6, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 6 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 7, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 7 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 8, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 8 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 9, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 9 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 10, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 10 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 11, result: (s = [10, 10], a = 1, r = 1.4856546892900455, sp = [10, 11], t = 10)\n",
      "agent 11 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 12, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 12 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 13, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 13 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 14, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 14 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 15, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 15 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 16, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 16 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 17, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 17 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 18, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 18 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 19, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 19 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 20, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 20 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 21, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 21 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 22, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 22 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 23, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 23 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 24, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 24 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 25, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 25 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 26, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 26 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 27, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 27 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 28, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 28 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 29, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 29 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 30, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 30 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 31, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 31 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 32, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 32 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 33, result: (s = [7, 10], a = 1, r = -2.4722356680409243, sp = [7, 11], t = 10)\n",
      "agent 33 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 34, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 34 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 35, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 35 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 36, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 36 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 37, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 37 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 38, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 38 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 39, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 39 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 40, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 40 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 41, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 41 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 42, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 42 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 43, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 43 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 44, result: (s = [8, 10], a = 1, r = 0.5791771670293088, sp = [8, 11], t = 10)\n",
      "agent 44 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 45, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 45 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 46, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 46 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 47, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 47 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 48, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 48 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 49, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 49 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 50, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 50 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 51, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 51 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 52, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 52 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 53, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 53 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 54, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 54 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 55, result: (s = [6, 10], a = 1, r = 2.9388284357563497, sp = [6, 11], t = 10)\n",
      "agent 55 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 56, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 56 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 57, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 57 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 58, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 58 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 59, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 59 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 60, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 60 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 61, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 61 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 62, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 62 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 63, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 63 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 64, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 64 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 65, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 65 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 66, result: (s = [3, 10], a = 1, r = -0.5763271311465279, sp = [3, 11], t = 10)\n",
      "agent 66 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 67, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 67 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 68, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 68 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 69, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 69 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 70, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 70 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 71, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 71 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 72, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 72 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 73, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 73 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 74, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 74 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 75, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 75 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 76, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 76 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 77, result: (s = [2, 10], a = 1, r = 0.815592049661168, sp = [2, 11], t = 10)\n",
      "agent 77 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 78, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 78 is done\n",
      "Updating priors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 1, t: 10, agent 79, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 79 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 80, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 80 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 81, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 81 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 82, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 82 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 83, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 83 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 84, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 84 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 85, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 85 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 86, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 86 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 87, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 87 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 88, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 88 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 89, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 89 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 90, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 90 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 91, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 91 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 92, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 92 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 93, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 93 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 94, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 94 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 95, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 95 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 96, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 96 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 97, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 97 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 98, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 98 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 99, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 99 is done\n",
      "Updating priors\n",
      "e: 1, t: 10, agent 100, result: (s = [9, 10], a = 1, r = -7.632423786961385, sp = [9, 11], t = 10)\n",
      "agent 100 is done\n",
      "Updating priors\n",
      "(e,i,t,st,r)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10×4 DataFrame\n",
       "│ Row │ run │ c   │ theta     │ std │\n",
       "│     │ \u001b[90mAny\u001b[39m │ \u001b[90mAny\u001b[39m │ \u001b[90mAny\u001b[39m       │ \u001b[90mAny\u001b[39m │\n",
       "├─────┼─────┼─────┼───────────┼─────┤\n",
       "│ 1   │ 1   │ 1   │ -4.54912  │ 1   │\n",
       "│ 2   │ 1   │ 2   │ 0.815592  │ 1   │\n",
       "│ 3   │ 1   │ 3   │ -0.576327 │ 1   │\n",
       "│ 4   │ 1   │ 4   │ 2.55318   │ 1   │\n",
       "│ 5   │ 1   │ 5   │ -3.81941  │ 1   │\n",
       "│ 6   │ 1   │ 6   │ 2.93883   │ 1   │\n",
       "│ 7   │ 1   │ 7   │ -2.47224  │ 1   │\n",
       "│ 8   │ 1   │ 8   │ 0.579177  │ 1   │\n",
       "│ 9   │ 1   │ 9   │ -7.63242  │ 1   │\n",
       "│ 10  │ 1   │ 10  │ 1.48565   │ 1   │, Any[(1, 1, 1, 1, [1, 1], 0), (1, 1, 1, 2, [10, 2], 0), (1, 1, 2, 1, [1, 1], 0), (1, 1, 1, 3, [10, 3], 0), (1, 1, 2, 2, [10, 2], 0), (1, 1, 3, 1, [1, 1], 0), (1, 1, 1, 4, [10, 4], 0), (1, 1, 2, 3, [10, 3], 0), (1, 1, 3, 2, [10, 2], 0), (1, 1, 4, 1, [1, 1], 0)  …  (1, 1, 97, 10, [9, 10], -8.46579), (1, 1, 98, 9, [9, 9], 0), (1, 1, 99, 8, [9, 8], 0), (1, 1, 100, 7, [9, 7], 0), (1, 1, 98, 10, [9, 10], -8.07567), (1, 1, 99, 9, [9, 9], 0), (1, 1, 100, 8, [9, 8], 0), (1, 1, 99, 10, [9, 10], -9.29565), (1, 1, 100, 9, [9, 9], 0), (1, 1, 100, 10, [9, 10], -8.15365)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_agents = 100\n",
    "num_chains = 10\n",
    "num_states = 10\n",
    "epochs = 1\n",
    "nruns = 1\n",
    "H = 30\n",
    "do_update_priors() = true\n",
    "true_values_list, runs = do_runs(nruns, num_agents, num_chains, num_states, H, do_update_priors, ucb_update_priors, ucb_mdp_builder)\n",
    "true_values_list, runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucb_update_priors (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using DataFrames\n",
    "using Statistics\n",
    "function ucb_update_priors(priors, hist)\n",
    "    # each state must be visted me times to update the prior\n",
    "    # me is # of S*D^2 s= states, D =diameter (https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9542/9919)\n",
    "    #     (D defined in http://www.jmlr.org/papers/volume11/jaksch10a/jaksch10a.pdf)\n",
    "    ## ^^^ Actually, think should just do this statistically, and if n > 2, then we can adjust the prior.\n",
    "    df = DataFrame(epoch = [x[1] for x in hist], agent=[x[2] for x in hist],\n",
    "               time = [x[3] for x in hist], chain = [x[4][1] for x in hist], chain_state = [x[4][2] for x in hist],\n",
    "        reward = [x[5] for x in hist])\n",
    "    new_theta = []\n",
    "    new_std = []\n",
    "    new_state = []\n",
    "    for arow in eachrow(priors)\n",
    "        if nrow(df[(df.chain.==arow.state[1]).&(df.chain_state.==arow.state[2]),:]) > 1\n",
    "            # print(\"df subset:\")\n",
    "            # println(df[(df.chain.==arow.state[1]).&(df.chain_state.==arow.state[2]),:])\n",
    "            # new mean = (s_p^2 /(s_s^2 + s_p^2 )) * mu_s + (s_s^2 /(s_s^2 + s_p^2 )) * mu_p\n",
    "            # new std = 1/(1/(s_p^2) + 1/(s_s^2)\n",
    "            mu_p = arow.theta\n",
    "            s_p_2 = arow.std^2\n",
    "            mu_s = mean(df[(df.chain.==arow.state[1]).&(df.chain_state.==arow.state[2]),:].reward)\n",
    "            s_s_2 = var(df[(df.chain.==arow.state[1]).&(df.chain_state.==arow.state[2]),:].reward)\n",
    "            # println(\"mu_p:$mu_p,s_p_2:$s_p_2,mu_s:$mu_s,s_s_2:$s_s_2\")\n",
    "            tmp_theta =  (s_p_2/(s_s_2 + s_p_2)) * mu_s + (s_s_2/(s_s_2 + s_p_2)) * mu_p\n",
    "            tmp_std = 1/(1/s_p_2 + 1/s_s_2)\n",
    "        else\n",
    "            tmp_theta =  arow.theta\n",
    "            tmp_std = arow.std\n",
    "        end\n",
    "        push!(new_state, arow.state)\n",
    "        push!(new_theta, tmp_theta)\n",
    "        push!(new_std, tmp_std)\n",
    "    end\n",
    "    new_priors = DataFrame(theta=new_theta, std=new_std, state=new_state)\n",
    "    #println(\"new priors: $new_priors\")\n",
    "    return new_priors\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(priors)\n",
    "ucb_update_priors(priors, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_average_regret (generic function with 2 methods)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_average_regret(results, chain_len, num_chains, theta)\n",
    "    df = DataFrame(run = [x[1] for x in results], epoch = [x[2] for x in results], agent=[x[3] for x in results],\n",
    "               time = [x[4] for x in results], c = [x[5][1] for x in results], state = [x[5][1] for x in results],\n",
    "               reward = [x[6] for x in results])\n",
    "    df_R = df[df.reward.>0,:]\n",
    "    th_max = by(theta, :run, :theta => maximum)\n",
    "    theta_joined = join(theta, th_max, on = :run)\n",
    "    df_joined = join(df_R, theta_joined, on = [:run,:c] )\n",
    "    # needs to be max theta\n",
    "    df_joined.Regret = df_joined.theta - df_joined.reward\n",
    "    df_joined\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>run</th><th>c</th><th>theta</th><th>std</th></tr><tr><th></th><th>Any</th><th>Any</th><th>Any</th><th>Any</th></tr></thead><tbody><p>10 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td>-4.54912</td><td>1</td></tr><tr><th>2</th><td>1</td><td>2</td><td>0.815592</td><td>1</td></tr><tr><th>3</th><td>1</td><td>3</td><td>-0.576327</td><td>1</td></tr><tr><th>4</th><td>1</td><td>4</td><td>2.55318</td><td>1</td></tr><tr><th>5</th><td>1</td><td>5</td><td>-3.81941</td><td>1</td></tr><tr><th>6</th><td>1</td><td>6</td><td>2.93883</td><td>1</td></tr><tr><th>7</th><td>1</td><td>7</td><td>-2.47224</td><td>1</td></tr><tr><th>8</th><td>1</td><td>8</td><td>0.579177</td><td>1</td></tr><tr><th>9</th><td>1</td><td>9</td><td>-7.63242</td><td>1</td></tr><tr><th>10</th><td>1</td><td>10</td><td>1.48565</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& run & c & theta & std\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & -4.54912 & 1 \\\\\n",
       "\t2 & 1 & 2 & 0.815592 & 1 \\\\\n",
       "\t3 & 1 & 3 & -0.576327 & 1 \\\\\n",
       "\t4 & 1 & 4 & 2.55318 & 1 \\\\\n",
       "\t5 & 1 & 5 & -3.81941 & 1 \\\\\n",
       "\t6 & 1 & 6 & 2.93883 & 1 \\\\\n",
       "\t7 & 1 & 7 & -2.47224 & 1 \\\\\n",
       "\t8 & 1 & 8 & 0.579177 & 1 \\\\\n",
       "\t9 & 1 & 9 & -7.63242 & 1 \\\\\n",
       "\t10 & 1 & 10 & 1.48565 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×4 DataFrame\n",
       "│ Row │ run │ c   │ theta     │ std │\n",
       "│     │ \u001b[90mAny\u001b[39m │ \u001b[90mAny\u001b[39m │ \u001b[90mAny\u001b[39m       │ \u001b[90mAny\u001b[39m │\n",
       "├─────┼─────┼─────┼───────────┼─────┤\n",
       "│ 1   │ 1   │ 1   │ -4.54912  │ 1   │\n",
       "│ 2   │ 1   │ 2   │ 0.815592  │ 1   │\n",
       "│ 3   │ 1   │ 3   │ -0.576327 │ 1   │\n",
       "│ 4   │ 1   │ 4   │ 2.55318   │ 1   │\n",
       "│ 5   │ 1   │ 5   │ -3.81941  │ 1   │\n",
       "│ 6   │ 1   │ 6   │ 2.93883   │ 1   │\n",
       "│ 7   │ 1   │ 7   │ -2.47224  │ 1   │\n",
       "│ 8   │ 1   │ 8   │ 0.579177  │ 1   │\n",
       "│ 9   │ 1   │ 9   │ -7.63242  │ 1   │\n",
       "│ 10  │ 1   │ 10  │ 1.48565   │ 1   │"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>run</th><th>epoch</th><th>agent</th><th>time</th><th>c</th><th>state</th><th>reward</th><th>theta</th><th>std</th><th>theta_maximum</th><th>Regret</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Real</th><th>Any</th><th>Any</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>41 rows × 11 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>10</td><td>10</td><td>10</td><td>2.353</td><td>1.48565</td><td>1</td><td>2.93883</td><td>-0.867347</td></tr><tr><th>2</th><td>1</td><td>1</td><td>2</td><td>10</td><td>10</td><td>10</td><td>0.583911</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.901744</td></tr><tr><th>3</th><td>1</td><td>1</td><td>3</td><td>10</td><td>10</td><td>10</td><td>0.991176</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.494479</td></tr><tr><th>4</th><td>1</td><td>1</td><td>4</td><td>10</td><td>10</td><td>10</td><td>0.58274</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.902914</td></tr><tr><th>5</th><td>1</td><td>1</td><td>5</td><td>10</td><td>10</td><td>10</td><td>2.35006</td><td>1.48565</td><td>1</td><td>2.93883</td><td>-0.864401</td></tr><tr><th>6</th><td>1</td><td>1</td><td>6</td><td>10</td><td>10</td><td>10</td><td>3.69753</td><td>1.48565</td><td>1</td><td>2.93883</td><td>-2.21188</td></tr><tr><th>7</th><td>1</td><td>1</td><td>7</td><td>10</td><td>10</td><td>10</td><td>2.01847</td><td>1.48565</td><td>1</td><td>2.93883</td><td>-0.532813</td></tr><tr><th>8</th><td>1</td><td>1</td><td>8</td><td>10</td><td>10</td><td>10</td><td>1.21392</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.271735</td></tr><tr><th>9</th><td>1</td><td>1</td><td>9</td><td>10</td><td>10</td><td>10</td><td>1.98799</td><td>1.48565</td><td>1</td><td>2.93883</td><td>-0.502334</td></tr><tr><th>10</th><td>1</td><td>1</td><td>10</td><td>10</td><td>10</td><td>10</td><td>0.968671</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.516984</td></tr><tr><th>11</th><td>1</td><td>1</td><td>11</td><td>10</td><td>10</td><td>10</td><td>0.925153</td><td>1.48565</td><td>1</td><td>2.93883</td><td>0.560501</td></tr><tr><th>12</th><td>1</td><td>1</td><td>34</td><td>10</td><td>8</td><td>8</td><td>0.542731</td><td>0.579177</td><td>1</td><td>2.93883</td><td>0.036446</td></tr><tr><th>13</th><td>1</td><td>1</td><td>35</td><td>10</td><td>8</td><td>8</td><td>0.721151</td><td>0.579177</td><td>1</td><td>2.93883</td><td>-0.141974</td></tr><tr><th>14</th><td>1</td><td>1</td><td>36</td><td>10</td><td>8</td><td>8</td><td>1.10045</td><td>0.579177</td><td>1</td><td>2.93883</td><td>-0.521273</td></tr><tr><th>15</th><td>1</td><td>1</td><td>37</td><td>10</td><td>8</td><td>8</td><td>1.47592</td><td>0.579177</td><td>1</td><td>2.93883</td><td>-0.896748</td></tr><tr><th>16</th><td>1</td><td>1</td><td>38</td><td>10</td><td>8</td><td>8</td><td>0.0656473</td><td>0.579177</td><td>1</td><td>2.93883</td><td>0.51353</td></tr><tr><th>17</th><td>1</td><td>1</td><td>41</td><td>10</td><td>8</td><td>8</td><td>0.499015</td><td>0.579177</td><td>1</td><td>2.93883</td><td>0.0801625</td></tr><tr><th>18</th><td>1</td><td>1</td><td>44</td><td>10</td><td>8</td><td>8</td><td>0.26374</td><td>0.579177</td><td>1</td><td>2.93883</td><td>0.315437</td></tr><tr><th>19</th><td>1</td><td>1</td><td>45</td><td>10</td><td>6</td><td>6</td><td>1.57738</td><td>2.93883</td><td>1</td><td>2.93883</td><td>1.36145</td></tr><tr><th>20</th><td>1</td><td>1</td><td>46</td><td>10</td><td>6</td><td>6</td><td>2.82437</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.114457</td></tr><tr><th>21</th><td>1</td><td>1</td><td>47</td><td>10</td><td>6</td><td>6</td><td>3.10467</td><td>2.93883</td><td>1</td><td>2.93883</td><td>-0.165837</td></tr><tr><th>22</th><td>1</td><td>1</td><td>48</td><td>10</td><td>6</td><td>6</td><td>2.53039</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.408438</td></tr><tr><th>23</th><td>1</td><td>1</td><td>49</td><td>10</td><td>6</td><td>6</td><td>1.92904</td><td>2.93883</td><td>1</td><td>2.93883</td><td>1.00978</td></tr><tr><th>24</th><td>1</td><td>1</td><td>50</td><td>10</td><td>6</td><td>6</td><td>2.39502</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.543805</td></tr><tr><th>25</th><td>1</td><td>1</td><td>51</td><td>10</td><td>6</td><td>6</td><td>1.7121</td><td>2.93883</td><td>1</td><td>2.93883</td><td>1.22672</td></tr><tr><th>26</th><td>1</td><td>1</td><td>52</td><td>10</td><td>6</td><td>6</td><td>2.39711</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.541716</td></tr><tr><th>27</th><td>1</td><td>1</td><td>53</td><td>10</td><td>6</td><td>6</td><td>2.25233</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.686494</td></tr><tr><th>28</th><td>1</td><td>1</td><td>54</td><td>10</td><td>6</td><td>6</td><td>2.2259</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.712932</td></tr><tr><th>29</th><td>1</td><td>1</td><td>55</td><td>10</td><td>6</td><td>6</td><td>2.61177</td><td>2.93883</td><td>1</td><td>2.93883</td><td>0.327059</td></tr><tr><th>30</th><td>1</td><td>1</td><td>57</td><td>10</td><td>3</td><td>3</td><td>1.84115</td><td>-0.576327</td><td>1</td><td>2.93883</td><td>-2.41747</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& run & epoch & agent & time & c & state & reward & theta & std & theta\\_maximum & Regret\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Real & Any & Any & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 10 & 10 & 10 & 2.353 & 1.48565 & 1 & 2.93883 & -0.867347 \\\\\n",
       "\t2 & 1 & 1 & 2 & 10 & 10 & 10 & 0.583911 & 1.48565 & 1 & 2.93883 & 0.901744 \\\\\n",
       "\t3 & 1 & 1 & 3 & 10 & 10 & 10 & 0.991176 & 1.48565 & 1 & 2.93883 & 0.494479 \\\\\n",
       "\t4 & 1 & 1 & 4 & 10 & 10 & 10 & 0.58274 & 1.48565 & 1 & 2.93883 & 0.902914 \\\\\n",
       "\t5 & 1 & 1 & 5 & 10 & 10 & 10 & 2.35006 & 1.48565 & 1 & 2.93883 & -0.864401 \\\\\n",
       "\t6 & 1 & 1 & 6 & 10 & 10 & 10 & 3.69753 & 1.48565 & 1 & 2.93883 & -2.21188 \\\\\n",
       "\t7 & 1 & 1 & 7 & 10 & 10 & 10 & 2.01847 & 1.48565 & 1 & 2.93883 & -0.532813 \\\\\n",
       "\t8 & 1 & 1 & 8 & 10 & 10 & 10 & 1.21392 & 1.48565 & 1 & 2.93883 & 0.271735 \\\\\n",
       "\t9 & 1 & 1 & 9 & 10 & 10 & 10 & 1.98799 & 1.48565 & 1 & 2.93883 & -0.502334 \\\\\n",
       "\t10 & 1 & 1 & 10 & 10 & 10 & 10 & 0.968671 & 1.48565 & 1 & 2.93883 & 0.516984 \\\\\n",
       "\t11 & 1 & 1 & 11 & 10 & 10 & 10 & 0.925153 & 1.48565 & 1 & 2.93883 & 0.560501 \\\\\n",
       "\t12 & 1 & 1 & 34 & 10 & 8 & 8 & 0.542731 & 0.579177 & 1 & 2.93883 & 0.036446 \\\\\n",
       "\t13 & 1 & 1 & 35 & 10 & 8 & 8 & 0.721151 & 0.579177 & 1 & 2.93883 & -0.141974 \\\\\n",
       "\t14 & 1 & 1 & 36 & 10 & 8 & 8 & 1.10045 & 0.579177 & 1 & 2.93883 & -0.521273 \\\\\n",
       "\t15 & 1 & 1 & 37 & 10 & 8 & 8 & 1.47592 & 0.579177 & 1 & 2.93883 & -0.896748 \\\\\n",
       "\t16 & 1 & 1 & 38 & 10 & 8 & 8 & 0.0656473 & 0.579177 & 1 & 2.93883 & 0.51353 \\\\\n",
       "\t17 & 1 & 1 & 41 & 10 & 8 & 8 & 0.499015 & 0.579177 & 1 & 2.93883 & 0.0801625 \\\\\n",
       "\t18 & 1 & 1 & 44 & 10 & 8 & 8 & 0.26374 & 0.579177 & 1 & 2.93883 & 0.315437 \\\\\n",
       "\t19 & 1 & 1 & 45 & 10 & 6 & 6 & 1.57738 & 2.93883 & 1 & 2.93883 & 1.36145 \\\\\n",
       "\t20 & 1 & 1 & 46 & 10 & 6 & 6 & 2.82437 & 2.93883 & 1 & 2.93883 & 0.114457 \\\\\n",
       "\t21 & 1 & 1 & 47 & 10 & 6 & 6 & 3.10467 & 2.93883 & 1 & 2.93883 & -0.165837 \\\\\n",
       "\t22 & 1 & 1 & 48 & 10 & 6 & 6 & 2.53039 & 2.93883 & 1 & 2.93883 & 0.408438 \\\\\n",
       "\t23 & 1 & 1 & 49 & 10 & 6 & 6 & 1.92904 & 2.93883 & 1 & 2.93883 & 1.00978 \\\\\n",
       "\t24 & 1 & 1 & 50 & 10 & 6 & 6 & 2.39502 & 2.93883 & 1 & 2.93883 & 0.543805 \\\\\n",
       "\t25 & 1 & 1 & 51 & 10 & 6 & 6 & 1.7121 & 2.93883 & 1 & 2.93883 & 1.22672 \\\\\n",
       "\t26 & 1 & 1 & 52 & 10 & 6 & 6 & 2.39711 & 2.93883 & 1 & 2.93883 & 0.541716 \\\\\n",
       "\t27 & 1 & 1 & 53 & 10 & 6 & 6 & 2.25233 & 2.93883 & 1 & 2.93883 & 0.686494 \\\\\n",
       "\t28 & 1 & 1 & 54 & 10 & 6 & 6 & 2.2259 & 2.93883 & 1 & 2.93883 & 0.712932 \\\\\n",
       "\t29 & 1 & 1 & 55 & 10 & 6 & 6 & 2.61177 & 2.93883 & 1 & 2.93883 & 0.327059 \\\\\n",
       "\t30 & 1 & 1 & 57 & 10 & 3 & 3 & 1.84115 & -0.576327 & 1 & 2.93883 & -2.41747 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "41×11 DataFrame. Omitted printing of 3 columns\n",
       "│ Row │ run   │ epoch │ agent │ time  │ c     │ state │ reward    │ theta     │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mReal\u001b[39m      │ \u001b[90mAny\u001b[39m       │\n",
       "├─────┼───────┼───────┼───────┼───────┼───────┼───────┼───────────┼───────────┤\n",
       "│ 1   │ 1     │ 1     │ 1     │ 10    │ 10    │ 10    │ 2.353     │ 1.48565   │\n",
       "│ 2   │ 1     │ 1     │ 2     │ 10    │ 10    │ 10    │ 0.583911  │ 1.48565   │\n",
       "│ 3   │ 1     │ 1     │ 3     │ 10    │ 10    │ 10    │ 0.991176  │ 1.48565   │\n",
       "│ 4   │ 1     │ 1     │ 4     │ 10    │ 10    │ 10    │ 0.58274   │ 1.48565   │\n",
       "│ 5   │ 1     │ 1     │ 5     │ 10    │ 10    │ 10    │ 2.35006   │ 1.48565   │\n",
       "│ 6   │ 1     │ 1     │ 6     │ 10    │ 10    │ 10    │ 3.69753   │ 1.48565   │\n",
       "│ 7   │ 1     │ 1     │ 7     │ 10    │ 10    │ 10    │ 2.01847   │ 1.48565   │\n",
       "│ 8   │ 1     │ 1     │ 8     │ 10    │ 10    │ 10    │ 1.21392   │ 1.48565   │\n",
       "│ 9   │ 1     │ 1     │ 9     │ 10    │ 10    │ 10    │ 1.98799   │ 1.48565   │\n",
       "│ 10  │ 1     │ 1     │ 10    │ 10    │ 10    │ 10    │ 0.968671  │ 1.48565   │\n",
       "⋮\n",
       "│ 31  │ 1     │ 1     │ 59    │ 10    │ 3     │ 3     │ 0.668976  │ -0.576327 │\n",
       "│ 32  │ 1     │ 1     │ 63    │ 10    │ 3     │ 3     │ 0.905845  │ -0.576327 │\n",
       "│ 33  │ 1     │ 1     │ 67    │ 10    │ 2     │ 2     │ 1.26295   │ 0.815592  │\n",
       "│ 34  │ 1     │ 1     │ 68    │ 10    │ 2     │ 2     │ 0.419381  │ 0.815592  │\n",
       "│ 35  │ 1     │ 1     │ 69    │ 10    │ 2     │ 2     │ 1.18237   │ 0.815592  │\n",
       "│ 36  │ 1     │ 1     │ 70    │ 10    │ 2     │ 2     │ 1.43727   │ 0.815592  │\n",
       "│ 37  │ 1     │ 1     │ 71    │ 10    │ 2     │ 2     │ 0.99818   │ 0.815592  │\n",
       "│ 38  │ 1     │ 1     │ 72    │ 10    │ 2     │ 2     │ 2.87912   │ 0.815592  │\n",
       "│ 39  │ 1     │ 1     │ 74    │ 10    │ 2     │ 2     │ 0.950067  │ 0.815592  │\n",
       "│ 40  │ 1     │ 1     │ 75    │ 10    │ 2     │ 2     │ 0.0651715 │ 0.815592  │\n",
       "│ 41  │ 1     │ 1     │ 76    │ 10    │ 2     │ 2     │ 0.98637   │ 0.815592  │"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain_len = num_states\n",
    "num_chains = num_chains\n",
    "get_average_regret(runs, chain_len, num_chains, true_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
